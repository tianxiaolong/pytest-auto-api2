#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Performance Monitor Module

This module provides performance monitor functionality.
"""

"""
æ€§èƒ½ç›‘æ§æ¨¡å—
æä¾›æµ‹è¯•æ‰§è¡Œæ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–åŠŸèƒ½

@Time   : 2023-12-20
@Author : txl
"""
import json
import threading
import time
from dataclasses import dataclass, field
from functools import wraps
from pathlib import Path
from typing import Any, Dict, List, Optional

import psutil


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""

    test_name: str
    start_time: float
    end_time: float
    duration: float
    cpu_usage: float
    memory_usage: float
    success: bool
    error_message: Optional[str] = None


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics: List[PerformanceMetrics] = []
        self.monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        self.system_metrics: List[Dict[str, Any]] = []

    def start_monitoring(self):
        """å¼€å§‹ç³»ç»Ÿç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_system)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()

    def stop_monitoring(self):
        """åœæ­¢ç³»ç»Ÿç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)

    def _monitor_system(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æº"""
        while self.monitoring:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()

                self.system_metrics.append(
                    {
                        "timestamp": time.time(),
                        "cpu_percent": cpu_percent,
                        "memory_percent": memory.percent,
                        "memory_used": memory.used,
                        "memory_available": memory.available,
                    }
                )

                # ä¿æŒæœ€è¿‘100ä¸ªæ•°æ®ç‚¹
                if len(self.system_metrics) > 100:
                    self.system_metrics.pop(0)

            except Exception:
                pass

            time.sleep(1)

    def record_test_performance(
        self, test_name: str, start_time: float, end_time: float, success: bool, error_message: Optional[str] = None
    ):
        """è®°å½•æµ‹è¯•æ€§èƒ½"""
        duration = end_time - start_time

        # è·å–å½“å‰ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        cpu_usage = psutil.cpu_percent()
        memory_usage = psutil.virtual_memory().percent

        metrics = PerformanceMetrics(
            test_name=test_name,
            start_time=start_time,
            end_time=end_time,
            duration=duration,
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            success=success,
            error_message=error_message,
        )

        self.metrics.append(metrics)

    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics:
            return {"message": "æš‚æ— æ€§èƒ½æ•°æ®"}

        durations = [m.duration for m in self.metrics]
        cpu_usages = [m.cpu_usage for m in self.metrics]
        memory_usages = [m.memory_usage for m in self.metrics]

        success_count = sum(1 for m in self.metrics if m.success)
        total_count = len(self.metrics)

        return {
            "total_tests": total_count,
            "success_tests": success_count,
            "success_rate": (success_count / total_count) * 100,
            "duration": {
                "total": sum(durations),
                "average": sum(durations) / len(durations),
                "min": min(durations),
                "max": max(durations),
            },
            "cpu_usage": {"average": sum(cpu_usages) / len(cpu_usages), "min": min(cpu_usages), "max": max(cpu_usages)},
            "memory_usage": {
                "average": sum(memory_usages) / len(memory_usages),
                "min": min(memory_usages),
                "max": max(memory_usages),
            },
            "slowest_tests": sorted(
                [(m.test_name, m.duration) for m in self.metrics], key=lambda x: x[1], reverse=True
            )[:5],
        }

    def save_performance_report(self, file_path: str = "performance_report.json"):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Š"""
        summary = self.get_performance_summary()

        report = {
            "summary": summary,
            "detailed_metrics": [
                {
                    "test_name": m.test_name,
                    "duration": m.duration,
                    "cpu_usage": m.cpu_usage,
                    "memory_usage": m.memory_usage,
                    "success": m.success,
                    "error_message": m.error_message,
                }
                for m in self.metrics
            ],
            "system_metrics": self.system_metrics[-50:],  # æœ€è¿‘50ä¸ªæ•°æ®ç‚¹
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)


# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
performance_monitor = PerformanceMonitor()


def monitor_performance(test_name: Optional[str] = None):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            name = test_name or f"{func.__module__}.{func.__name__}"
            start_time = time.time()
            success = True
            error_message = None

            try:
                result = func(*args, **kwargs)
                return result
            except Exception as e:
                success = False
                error_message = str(e)
                raise
            finally:
                end_time = time.time()
                performance_monitor.record_test_performance(name, start_time, end_time, success, error_message)

        return wrapper

    return decorator


class TestDataCache:
    """æµ‹è¯•æ•°æ®ç¼“å­˜"""

    def __init__(self, max_size: int = 100):
        self.cache: Dict[str, Any] = {}
        self.access_times: Dict[str, float] = {}
        self.max_size = max_size

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self.cache:
            self.access_times[key] = time.time()
            return self.cache[key]
        return None

    def set(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€ä¹…æœªè®¿é—®çš„æ•°æ®
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
            self.remove(oldest_key)

        self.cache[key] = value
        self.access_times[key] = time.time()

    def remove(self, key: str):
        """åˆ é™¤ç¼“å­˜æ•°æ®"""
        if key in self.cache:
            del self.cache[key]
            del self.access_times[key]

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.access_times.clear()

    def size(self) -> int:
        """è·å–ç¼“å­˜å¤§å°"""
        return len(self.cache)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return {
            "size": self.size(),
            "max_size": self.max_size,
            "keys": list(self.cache.keys()),
            "usage_rate": (self.size() / self.max_size) * 100,
        }


# å…¨å±€æµ‹è¯•æ•°æ®ç¼“å­˜å®ä¾‹
test_data_cache = TestDataCache()


def cached_test_data(cache_key: Optional[str] = None, ttl: int = 3600):
    """æµ‹è¯•æ•°æ®ç¼“å­˜è£…é¥°å™¨"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            key = cache_key or f"{func.__module__}.{func.__name__}:{hash(str(args) + str(kwargs))}"

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = test_data_cache.get(key)
            if cached_result is not None:
                return cached_result

            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            test_data_cache.set(key, result)

            return result

        return wrapper

    return decorator


def optimize_test_execution():
    """ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œ"""
    # å¯åŠ¨æ€§èƒ½ç›‘æ§
    performance_monitor.start_monitoring()

    # è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆä»…åœ¨æ”¯æŒçš„ç³»ç»Ÿä¸Šï¼‰
    try:
        import os

        if hasattr(os, "nice"):
            os.nice(-5)  # æé«˜ä¼˜å…ˆçº§
    except (OSError, AttributeError):
        pass

    # é¢„çƒ­JITç¼–è¯‘å™¨ï¼ˆå¦‚æœä½¿ç”¨PyPyï¼‰
    try:
        import __pypy__

        # PyPyç‰¹å®šçš„ä¼˜åŒ–
        pass
    except ImportError:
        pass


def cleanup_performance_monitoring():
    """æ¸…ç†æ€§èƒ½ç›‘æ§"""
    performance_monitor.stop_monitoring()

    # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
    try:
        performance_monitor.save_performance_report()
        print("ğŸ“Š æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ° performance_report.json")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")

    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    cache_stats = test_data_cache.get_stats()
    print(f"ğŸ’¾ ç¼“å­˜ç»Ÿè®¡: {cache_stats}")


if __name__ == "__main__":
    # æµ‹è¯•æ€§èƒ½ç›‘æ§
    @monitor_performance("test_example")
    def test_function():
        time.sleep(0.1)
        return "test result"

    optimize_test_execution()

    # è¿è¡Œæµ‹è¯•
    for i in range(5):
        test_function()

    # æ˜¾ç¤ºæ€§èƒ½æ‘˜è¦
    summary = performance_monitor.get_performance_summary()
    print("æ€§èƒ½æ‘˜è¦:", summary)

    cleanup_performance_monitoring()
