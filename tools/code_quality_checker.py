#!/usr/bin/env python
# -*- coding: utf-8 -*-
from pathlib import Path
import ast
import re
import sys

from typing import Any, Dict, List, Tuple
import subprocess

"""
ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·
æä¾›ä»£ç è´¨é‡æ£€æŸ¥ã€æ ¼å¼åŒ–å’Œä¼˜åŒ–å»ºè®®

@Time   : 2023-12-20
@Author : txl
"""


class CodeQualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.issues = []
        self.suggestions = []

    def check_python_syntax(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥Pythonè¯­æ³•"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            try:
                ast.parse(content)
            except SyntaxError as e:
                issues.append(f"è¯­æ³•é”™è¯¯ {file_path}:{e.lineno}: {e.msg}")
        except Exception as e:
            issues.append(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

        return issues

    def check_import_style(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥å¯¼å…¥é£Žæ ¼"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            import_section_ended = False
            for i, line in enumerate(lines, 1):
                line = line.strip()

                # æ£€æŸ¥å¯¼å…¥é¡ºåº
                if line.startswith("import ") or line.startswith("from "):
                    if import_section_ended:
                        issues.append(f"{file_path}:{i}: å¯¼å…¥è¯­å¥åº”è¯¥åœ¨æ–‡ä»¶é¡¶éƒ¨")
                elif line and not line.startswith("#") and not line.startswith('"""') and not line.startswith("'''"):
                    import_section_ended = True

                # æ£€æŸ¥ç›¸å¯¹å¯¼å…¥
                if line.startswith("from ."):
                    continue  # ç›¸å¯¹å¯¼å…¥æ˜¯å…è®¸çš„

                # æ£€æŸ¥é€šé…ç¬¦å¯¼å…¥
                if "import *" in line:
                    issues.append(f"{file_path}:{i}: é¿å…ä½¿ç”¨é€šé…ç¬¦å¯¼å…¥ (import *)")

        except Exception as e:
            issues.append(f"æ£€æŸ¥å¯¼å…¥é£Žæ ¼å¤±è´¥ {file_path}: {e}")

        return issues

    def check_function_complexity(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥å‡½æ•°å¤æ‚åº¦"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # è®¡ç®—å‡½æ•°è¡Œæ•°
                    if hasattr(node, "end_lineno") and node.end_lineno:
                        lines = node.end_lineno - node.lineno
                        if lines > 50:
                            issues.append(
                                f"{file_path}:{node.lineno}: " f"å‡½æ•° '{node.name}' è¿‡é•¿ ({lines} è¡Œ)ï¼Œå»ºè®®æ‹†åˆ†"
                            )

                    # æ£€æŸ¥å‚æ•°æ•°é‡
                    arg_count = len(node.args.args)
                    if arg_count > 7:
                        issues.append(
                            f"{file_path}:{node.lineno}: " f"å‡½æ•° '{node.name}' å‚æ•°è¿‡å¤š ({arg_count} ä¸ª)ï¼Œå»ºè®®é‡æž„"
                        )

        except Exception as e:
            issues.append(f"æ£€æŸ¥å‡½æ•°å¤æ‚åº¦å¤±è´¥ {file_path}: {e}")

        return issues

    def check_docstrings(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)

            # æ£€æŸ¥æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
            if not ast.get_docstring(tree):
                issues.append(f"{file_path}: ç¼ºå°‘æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²")

            # æ£€æŸ¥ç±»å’Œå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                    if not ast.get_docstring(node):
                        node_type = "å‡½æ•°" if isinstance(node, ast.FunctionDef) else "ç±»"
                        issues.append(f"{file_path}:{node.lineno}: " f"{node_type} '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²")

        except Exception as e:
            issues.append(f"æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²å¤±è´¥ {file_path}: {e}")

        return issues

    def check_naming_conventions(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # å‡½æ•°ååº”è¯¥æ˜¯snake_caseï¼Œä½†æŽ’é™¤HTTPå¤„ç†å™¨çš„æ ‡å‡†æ–¹æ³•
                    http_handler_methods = {
                        "do_GET",
                        "do_POST",
                        "do_PUT",
                        "do_DELETE",
                        "do_HEAD",
                        "do_OPTIONS",
                        "do_PATCH",
                        "do_TRACE",
                        "do_CONNECT",
                    }

                    if node.name not in http_handler_methods and not re.match(r"^[a-z_][a-z0-9_]*$", node.name):
                        issues.append(f"{file_path}:{node.lineno}: " f"å‡½æ•°å '{node.name}' åº”ä½¿ç”¨snake_caseå‘½å")

                elif isinstance(node, ast.ClassDef):
                    # ç±»ååº”è¯¥æ˜¯PascalCase
                    if not re.match(r"^[A-Z][a-zA-Z0-9]*$", node.name):
                        issues.append(f"{file_path}:{node.lineno}: " f"ç±»å '{node.name}' åº”ä½¿ç”¨PascalCaseå‘½å")

                elif isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):
                    # å˜é‡ååº”è¯¥æ˜¯snake_caseï¼ˆæŽ’é™¤å¸¸é‡ï¼‰
                    if (
                            not node.id.isupper()
                            and not re.match(r"^[a-z_][a-z0-9_]*$", node.id)
                            and not node.id.startswith("_")
                    ):
                        issues.append(f"{file_path}:{node.lineno}: " f"å˜é‡å '{node.id}' åº”ä½¿ç”¨snake_caseå‘½å")

        except Exception as e:
            issues.append(f"æ£€æŸ¥å‘½åè§„èŒƒå¤±è´¥ {file_path}: {e}")

        return issues

    def check_line_length(self, file_path: Path, max_length: int = 120) -> List[str]:
        """æ£€æŸ¥è¡Œé•¿åº¦"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            for i, line in enumerate(lines, 1):
                if len(line.rstrip()) > max_length:
                    issues.append(f"{file_path}:{i}: " f"è¡Œé•¿åº¦è¶…è¿‡ {max_length} å­—ç¬¦ ({len(line.rstrip())} å­—ç¬¦)")

        except Exception as e:
            issues.append(f"æ£€æŸ¥è¡Œé•¿åº¦å¤±è´¥ {file_path}: {e}")

        return issues

    def check_security_issues(self, file_path: Path) -> List[str]:
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç 
            password_patterns = [
                r'password\s*=\s*["\'][^"\']+["\']',
                r'passwd\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']',
                r'token\s*=\s*["\'][^"\']+["\']',
            ]

            lines = content.split("\n")
            for i, line in enumerate(lines, 1):
                for pattern in password_patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append(f"{file_path}:{i}: " "å¯èƒ½åŒ…å«ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯")

            # æ£€æŸ¥SQLæ³¨å…¥é£Žé™©
            if "execute(" in content and "%" in content:
                issues.append(f"{file_path}: å¯èƒ½å­˜åœ¨SQLæ³¨å…¥é£Žé™©ï¼Œå»ºè®®ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢")

            # æ£€æŸ¥evalä½¿ç”¨
            if "eval(" in content:
                issues.append(f"{file_path}: ä½¿ç”¨eval()å¯èƒ½å­˜åœ¨å®‰å…¨é£Žé™©")

        except Exception as e:
            issues.append(f"æ£€æŸ¥å®‰å…¨é—®é¢˜å¤±è´¥ {file_path}: {e}")

        return issues

    def run_external_tools(self, file_path: Path) -> List[str]:
        """è¿è¡Œå¤–éƒ¨ä»£ç è´¨é‡å·¥å…·"""
        issues = []

        # å°è¯•è¿è¡Œflake8
        try:
            result = subprocess.run(
                ["flake8", str(file_path), "--max-line-length=120"], capture_output=True, text=True, timeout=30
            )
            if result.stdout:
                issues.extend(result.stdout.strip().split("\n"))
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass

        return issues

    def check_file(self, file_path: Path) -> Dict[str, List[str]]:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
        if not file_path.suffix == ".py":
            return {}

        if "venv" in str(file_path) or "__pycache__" in str(file_path):
            return {}

        results = {
            "syntax": self.check_python_syntax(file_path),
            "imports": self.check_import_style(file_path),
            "complexity": self.check_function_complexity(file_path),
            "docstrings": self.check_docstrings(file_path),
            "naming": self.check_naming_conventions(file_path),
            "line_length": self.check_line_length(file_path),
            "security": self.check_security_issues(file_path),
            "external": self.run_external_tools(file_path),
        }

        return {k: v for k, v in results.items() if v}

    def check_project(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•´ä¸ªé¡¹ç›®"""
        print("ðŸ” å¼€å§‹ä»£ç è´¨é‡æ£€æŸ¥...")

        python_files = list(self.project_root.rglob("*.py"))
        total_issues = 0
        file_results = {}

        for py_file in python_files:
            if "venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            file_issues = self.check_file(py_file)
            if file_issues:
                file_results[str(py_file)] = file_issues
                total_issues += sum(len(issues) for issues in file_issues.values())

        # ç”Ÿæˆæ‘˜è¦
        summary = {
            "total_files_checked": len(
                [f for f in python_files if "venv" not in str(f) and "__pycache__" not in str(f)]
            ),
            "files_with_issues": len(file_results),
            "total_issues": total_issues,
            "issue_types": {},
        }

        # ç»Ÿè®¡é—®é¢˜ç±»åž‹
        for file_issues in file_results.values():
            for issue_type, issues in file_issues.items():
                if issue_type not in summary["issue_types"]:
                    summary["issue_types"][issue_type] = 0
                summary["issue_types"][issue_type] += len(issues)

        return {"summary": summary, "file_results": file_results, "suggestions": self.generate_suggestions(summary)}

    def generate_suggestions(self, summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        if summary["total_issues"] == 0:
            suggestions.append("ðŸŽ‰ ä»£ç è´¨é‡æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘çŽ°é—®é¢˜ï¼")
            return suggestions

        suggestions.append(f"ðŸ“Š å‘çŽ° {summary['total_issues']} ä¸ªé—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–ï¼š")

        issue_types = summary.get("issue_types", {})

        if "syntax" in issue_types:
            suggestions.append("ðŸ”§ ä¿®å¤è¯­æ³•é”™è¯¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰")

        if "security" in issue_types:
            suggestions.append("ðŸ”’ ä¿®å¤å®‰å…¨é—®é¢˜ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰")

        if "docstrings" in issue_types:
            suggestions.append("ðŸ“ æ·»åŠ ç¼ºå¤±çš„æ–‡æ¡£å­—ç¬¦ä¸²")

        if "naming" in issue_types:
            suggestions.append("ðŸ·ï¸ ä¿®æ­£å‘½åè§„èŒƒé—®é¢˜")

        if "complexity" in issue_types:
            suggestions.append("ðŸ”„ é‡æž„å¤æ‚å‡½æ•°")

        if "line_length" in issue_types:
            suggestions.append("ðŸ“ è°ƒæ•´è¿‡é•¿çš„ä»£ç è¡Œ")

        if "imports" in issue_types:
            suggestions.append("ðŸ“¦ ä¼˜åŒ–å¯¼å…¥è¯­å¥")

        suggestions.extend(
            [
                "",
                "ðŸ’¡ æŽ¨èå·¥å…·:",
                "   - ä½¿ç”¨ black è¿›è¡Œä»£ç æ ¼å¼åŒ–",
                "   - ä½¿ç”¨ isort æ•´ç†å¯¼å…¥è¯­å¥",
                "   - ä½¿ç”¨ mypy è¿›è¡Œç±»åž‹æ£€æŸ¥",
                "   - é…ç½® pre-commit é’©å­è‡ªåŠ¨æ£€æŸ¥",
            ]
        )

        return suggestions

    def save_report(self, results: Dict[str, Any], file_path: str = "code_quality_report.json"):
        """ä¿å­˜æ£€æŸ¥æŠ¥å‘Š"""
        import json

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ðŸ“„ ä»£ç è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")


def main():
    """ä¸»å‡½æ•°"""
    checker = CodeQualityChecker()
    results = checker.check_project()

    # æ˜¾ç¤ºæ‘˜è¦
    summary = results["summary"]
    print("\nðŸ“‹ ä»£ç è´¨é‡æ£€æŸ¥æ‘˜è¦:")
    print(f"   æ£€æŸ¥æ–‡ä»¶æ•°: {summary['total_files_checked']}")
    print(f"   æœ‰é—®é¢˜æ–‡ä»¶: {summary['files_with_issues']}")
    print(f"   é—®é¢˜æ€»æ•°: {summary['total_issues']}")

    if summary["issue_types"]:
        print("   é—®é¢˜åˆ†å¸ƒ:")
        for issue_type, count in summary["issue_types"].items():
            print(f"     {issue_type}: {count}")

    # æ˜¾ç¤ºå»ºè®®
    print("\nðŸ’¡ æ”¹è¿›å»ºè®®:")
    for suggestion in results["suggestions"]:
        print(suggestion)

    # ä¿å­˜æŠ¥å‘Š
    checker.save_report(results)

    # è¿”å›žé€€å‡ºç 
    return 1 if summary["total_issues"] > 0 else 0


if __name__ == "__main__":
    sys.exit(main())
