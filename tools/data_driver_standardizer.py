#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®é©±åŠ¨æ ‡å‡†åŒ–å·¥å…·

æ£€æŸ¥å¹¶ä¿®å¤é¡¹ç›®ä¸­æ‰€æœ‰çš„æ•°æ®é©±åŠ¨é…ç½®ï¼Œç¡®ä¿ï¼š
1. ç»Ÿä¸€ä½¿ç”¨æ–°çš„get_test_data()æ¥å£
2. ç§»é™¤æ—§çš„ç¡¬ç¼–ç case_idæ–¹å¼
3. ç¡®ä¿æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½æŒ‡å®šå…·ä½“çš„æ•°æ®æ–‡ä»¶å
4. æ£€æŸ¥è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç æ˜¯å¦ç¬¦åˆæ ‡å‡†
"""

import re
import ast
from pathlib import Path
from typing import Dict, List, Any, Tuple


class DataDriverStandardizer:
    """æ•°æ®é©±åŠ¨æ ‡å‡†åŒ–å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨"""
        self.project_root = Path(__file__).parent.parent
        self.test_case_dir = self.project_root / "test_case"

        self.issues_found = []
        self.fixes_applied = []

    def find_all_python_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []

        # æµ‹è¯•æ–‡ä»¶
        for test_file in self.test_case_dir.rglob("*.py"):
            if "__pycache__" not in str(test_file):
                python_files.append(test_file)

        # å…¶ä»–å¯èƒ½åŒ…å«æ•°æ®é©±åŠ¨ä»£ç çš„æ–‡ä»¶
        for py_file in self.project_root.rglob("*.py"):
            if (
                "__pycache__" not in str(py_file) and
                "venv" not in str(py_file) and
                ".git" not in str(py_file) and
                py_file not in python_files
            ):
                # åªæ£€æŸ¥å¯èƒ½åŒ…å«æµ‹è¯•ç›¸å…³ä»£ç çš„æ–‡ä»¶
                if any(keyword in py_file.name.lower() for keyword in
                       ['test', 'case', 'data', 'driver']):
                    python_files.append(py_file)

        return python_files

    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„æ•°æ®é©±åŠ¨é…ç½®"""
        result = {
            'file': str(file_path.relative_to(self.project_root)),
            'issues': [],
            'old_patterns': [],
            'new_patterns': [],
            'needs_fix': False,
            'content': ''
        }

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                result['content'] = content

            # æ£€æŸ¥æ—§çš„æ•°æ®è·å–æ–¹å¼
            self._check_old_patterns(content, result)

            # æ£€æŸ¥æ–°çš„æ•°æ®è·å–æ–¹å¼
            self._check_new_patterns(content, result)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤
            if result['old_patterns'] or any('æœªæŒ‡å®šæ–‡ä»¶å' in issue for issue in result['issues']):
                result['needs_fix'] = True

        except Exception as e:
            result['issues'].append(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

        return result

    def _check_old_patterns(self, content: str, result: Dict[str, Any]):
        """æ£€æŸ¥æ—§çš„æ•°æ®è·å–æ¨¡å¼"""

        # 1. æ£€æŸ¥ç¡¬ç¼–ç çš„case_idåˆ—è¡¨
        case_id_pattern = r"case_id\s*=\s*\[([^\]]+)\]"
        matches = re.findall(case_id_pattern, content)
        for match in matches:
            result['old_patterns'].append({
                'type': 'hardcoded_case_id',
                'pattern': f"case_id = [{match}]",
                'line': self._find_line_number(content, f"case_id = [{match}]")
            })
            result['issues'].append("å‘ç°ç¡¬ç¼–ç çš„case_idåˆ—è¡¨ï¼Œå»ºè®®ä½¿ç”¨get_test_data()")

        # 2. æ£€æŸ¥GetTestCase.case_data()è°ƒç”¨
        get_test_case_pattern = r"GetTestCase\.case_data\([^)]+\)"
        matches = re.findall(get_test_case_pattern, content)
        for match in matches:
            result['old_patterns'].append({
                'type': 'get_test_case',
                'pattern': match,
                'line': self._find_line_number(content, match)
            })
            result['issues'].append("å‘ç°æ—§çš„GetTestCase.case_data()è°ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨get_test_data()")

        # 3. æ£€æŸ¥æ—§çš„å¯¼å…¥
        # æ—§çš„å¯¼å…¥ï¼ˆè¿™äº›æ˜¯æ£€æµ‹æ¨¡å¼ï¼Œä¸æ˜¯å®é™…å¯¼å…¥ï¼‰
        old_imports = [
            "from utils.read_files_tools.get_yaml_data_analysis import GetTestCase",
            "from utils.read_files_tools.get_yaml_data_analysis import CaseData"
        ]
        for old_import in old_imports:
            if old_import in content:
                result['old_patterns'].append({
                    'type': 'old_import',
                    'pattern': old_import,
                    'line': self._find_line_number(content, old_import)
                })
                result['issues'].append(f"å‘ç°æ—§çš„å¯¼å…¥: {old_import}")

    def _check_new_patterns(self, content: str, result: Dict[str, Any]):
        """æ£€æŸ¥æ–°çš„æ•°æ®è·å–æ¨¡å¼"""

        # æ£€æŸ¥get_test_dataè°ƒç”¨
        get_test_data_pattern = r'get_test_data\s*\(\s*["\']([^"\']+)["\'](?:\s*,\s*["\']([^"\']*)["\'])?\s*\)'
        matches = re.findall(get_test_data_pattern, content)

        for match in matches:
            module_name = match[0]
            file_name = match[1] if len(match) > 1 and match[1] else None

            pattern_info = {
                'type': 'get_test_data',
                'module': module_name,
                'file_name': file_name,
                'has_file_name': file_name is not None and file_name != '',
                'line': self._find_line_number(content, f"get_test_data('{module_name}'")
            }

            result['new_patterns'].append(pattern_info)

            if not pattern_info['has_file_name']:
                result['issues'].append(f"get_test_data('{module_name}')æœªæŒ‡å®šæ–‡ä»¶å")

    def _find_line_number(self, content: str, pattern: str) -> int:
        """æŸ¥æ‰¾æ¨¡å¼åœ¨æ–‡ä»¶ä¸­çš„è¡Œå·"""
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            if pattern in line:
                return i
        return 0

    def generate_fix_suggestions(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions = []

        # é’ˆå¯¹æ—§æ¨¡å¼çš„ä¿®å¤å»ºè®®
        for old_pattern in analysis_result['old_patterns']:
            if old_pattern['type'] == 'hardcoded_case_id':
                suggestions.append(
                    f"è¡Œ {old_pattern['line']}: å°†ç¡¬ç¼–ç çš„case_idæ›¿æ¢ä¸ºget_test_data()è°ƒç”¨"
                )
            elif old_pattern['type'] == 'get_test_case':
                suggestions.append(
                    f"è¡Œ {old_pattern['line']}: å°†GetTestCase.case_data()æ›¿æ¢ä¸ºget_test_data()"
                )
            elif old_pattern['type'] == 'old_import':
                suggestions.append(
                    f"è¡Œ {old_pattern['line']}: ç§»é™¤æ—§çš„å¯¼å…¥ï¼Œæ·»åŠ æ–°çš„å¯¼å…¥"
                )

        # é’ˆå¯¹æ–°æ¨¡å¼çš„ä¿®å¤å»ºè®®
        for new_pattern in analysis_result['new_patterns']:
            if not new_pattern['has_file_name']:
                # æ ¹æ®æ–‡ä»¶è·¯å¾„æ¨æ–­åº”è¯¥ä½¿ç”¨çš„æ–‡ä»¶å
                file_path = analysis_result['file']
                if 'test_case' in file_path:
                    module = new_pattern['module']
                    suggested_file = self._suggest_file_name(file_path, module)
                    suggestions.append(
                        f"è¡Œ {new_pattern['line']}: ä¸ºget_test_data('{module}')æŒ‡å®šæ–‡ä»¶å: '{suggested_file}'"
                    )

        return suggestions

    def _suggest_file_name(self, file_path: str, module: str) -> str:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„å’Œæ¨¡å—åæ¨æ–­æ•°æ®æ–‡ä»¶å"""
        file_name = Path(file_path).stem

        # ç§»é™¤test_å‰ç¼€
        if file_name.startswith('test_'):
            base_name = file_name[5:]
        else:
            base_name = file_name

        # æ ¹æ®æ¨¡å—å’Œæ–‡ä»¶åæ¨æ–­
        if module.lower() == 'login':
            return 'login.yaml'
        elif module.lower() == 'userinfo':
            return 'get_user_info.yaml'
        elif module.lower() == 'collect':
            if 'addtool' in base_name:
                return 'collect_addtool.yaml'
            elif 'delete' in base_name:
                return 'collect_delete_tool.yaml'
            elif 'update' in base_name:
                return 'collect_update_tool.yaml'
            elif 'list' in base_name:
                return 'collect_tool_list.yaml'
            else:
                return 'collect_addtool.yaml'  # é»˜è®¤

        return f"{base_name}.yaml"

    def run_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢åˆ†æ"""
        print("ğŸ” å¼€å§‹æ•°æ®é©±åŠ¨æ ‡å‡†åŒ–åˆ†æ...")

        python_files = self.find_all_python_files()
        results = []

        print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

        for py_file in python_files:
            # è·³è¿‡åˆ†æå·¥å…·æœ¬èº«ï¼Œé¿å…æ£€æµ‹åˆ°å·¥å…·ä¸­çš„ç¤ºä¾‹æ¨¡å¼
            if py_file.name == 'data_driver_standardizer.py':
                continue

            print(f"  ğŸ“„ åˆ†æ: {py_file.relative_to(self.project_root)}")
            result = self.analyze_file(py_file)
            if result['issues'] or result['old_patterns']:
                results.append(result)

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        summary = self._generate_summary(results)

        return {
            'files_analyzed': len(python_files),
            'files_with_issues': len(results),
            'detailed_results': results,
            'summary': summary
        }

    def _generate_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ±‡æ€»ä¿¡æ¯"""
        summary = {
            'total_issues': 0,
            'old_pattern_count': 0,
            'missing_file_name_count': 0,
            'files_need_fix': 0,
            'issue_types': {}
        }

        for result in results:
            summary['total_issues'] += len(result['issues'])
            summary['old_pattern_count'] += len(result['old_patterns'])

            if result['needs_fix']:
                summary['files_need_fix'] += 1

            # ç»Ÿè®¡é—®é¢˜ç±»å‹
            for issue in result['issues']:
                if 'ç¡¬ç¼–ç ' in issue:
                    summary['issue_types']['hardcoded_case_id'] = summary['issue_types'].get('hardcoded_case_id', 0) + 1
                elif 'GetTestCase' in issue:
                    summary['issue_types']['old_get_test_case'] = summary['issue_types'].get('old_get_test_case', 0) + 1
                elif 'æœªæŒ‡å®šæ–‡ä»¶å' in issue:
                    summary['issue_types']['missing_file_name'] = summary['issue_types'].get('missing_file_name', 0) + 1
                    summary['missing_file_name_count'] += 1

        return summary

    def print_detailed_report(self, analysis_result: Dict[str, Any]):
        """æ‰“å°è¯¦ç»†æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æ•°æ®é©±åŠ¨æ ‡å‡†åŒ–åˆ†ææŠ¥å‘Š")
        print("=" * 80)

        summary = analysis_result['summary']

        # æ€»ä½“ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  åˆ†ææ–‡ä»¶æ•°: {analysis_result['files_analyzed']}")
        print(f"  æœ‰é—®é¢˜çš„æ–‡ä»¶: {analysis_result['files_with_issues']}")
        print(f"  éœ€è¦ä¿®å¤çš„æ–‡ä»¶: {summary['files_need_fix']}")
        print(f"  å‘ç°é—®é¢˜æ€»æ•°: {summary['total_issues']}")

        # é—®é¢˜ç±»å‹ç»Ÿè®¡
        if summary['issue_types']:
            print(f"\nğŸ“‹ é—®é¢˜ç±»å‹ç»Ÿè®¡:")
            for issue_type, count in summary['issue_types'].items():
                type_name = {
                    'hardcoded_case_id': 'ç¡¬ç¼–ç case_id',
                    'old_get_test_case': 'æ—§çš„GetTestCaseè°ƒç”¨',
                    'missing_file_name': 'æœªæŒ‡å®šæ–‡ä»¶å'
                }.get(issue_type, issue_type)
                print(f"  {type_name}: {count} ä¸ª")

        # è¯¦ç»†é—®é¢˜
        if analysis_result['files_with_issues'] > 0:
            print(f"\nâŒ è¯¦ç»†é—®é¢˜:")
            for result in analysis_result['detailed_results']:
                print(f"\n  ğŸ“„ {result['file']}:")

                # æ˜¾ç¤ºé—®é¢˜
                for issue in result['issues']:
                    print(f"    âŒ {issue}")

                # æ˜¾ç¤ºæ—§æ¨¡å¼
                for old_pattern in result['old_patterns']:
                    print(f"    ğŸ”´ æ—§æ¨¡å¼ (è¡Œ{old_pattern['line']}): {old_pattern['pattern'][:60]}...")

                # æ˜¾ç¤ºä¿®å¤å»ºè®®
                suggestions = self.generate_fix_suggestions(result)
                if suggestions:
                    print(f"    ğŸ’¡ ä¿®å¤å»ºè®®:")
                    for suggestion in suggestions:
                        print(f"      - {suggestion}")

        # æ€»ä½“å»ºè®®
        print(f"\nğŸ”§ æ€»ä½“å»ºè®®:")
        print(f"  1. ç»Ÿä¸€ä½¿ç”¨get_test_data()æ¥å£æ›¿ä»£æ—§çš„æ•°æ®è·å–æ–¹å¼")
        print(f"  2. ä¸ºæ‰€æœ‰get_test_data()è°ƒç”¨æŒ‡å®šå…·ä½“çš„æ–‡ä»¶å")
        print(f"  3. ç§»é™¤ç¡¬ç¼–ç çš„case_idåˆ—è¡¨")
        print(f"  4. æ›´æ–°å¯¼å…¥è¯­å¥ä½¿ç”¨æ–°çš„æ¥å£")
        print(f"  5. æ£€æŸ¥è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç æ˜¯å¦ç¬¦åˆæ–°æ ‡å‡†")


def main():
    """ä¸»å‡½æ•°"""
    standardizer = DataDriverStandardizer()
    result = standardizer.run_analysis()
    standardizer.print_detailed_report(result)

    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    if result['files_with_issues'] == 0:
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®é©±åŠ¨é…ç½®å·²æ ‡å‡†åŒ–ï¼")
        return 0
    else:
        print(f"\nâš ï¸ å‘ç° {result['files_with_issues']} ä¸ªæ–‡ä»¶éœ€è¦æ ‡å‡†åŒ–ï¼")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
