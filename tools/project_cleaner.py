#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os
import shutil
import sys
from pathlib import Path
from typing import List, Dict, Any, Set
import json
import time

"""
é¡¹ç›®æ¸…ç†å·¥å…·
å®‰å…¨æ¸…ç†ç¼“å­˜ã€å†å²æ•°æ®å’Œæ— ç”¨æ–‡ä»¶

@Time   : 2023-12-20
@Author : txl
"""


class ProjectCleaner:
    """é¡¹ç›®æ¸…ç†å™¨"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.cleaned_files = []
        self.cleaned_dirs = []
        self.saved_space = 0
        self.stats = {
            'cache_files': 0,
            'log_files': 0,
            'report_files': 0,
            'temp_files': 0,
            'duplicate_docs': 0,
            'old_scripts': 0
        }

        # å®šä¹‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶å’Œç›®å½•
        self.cleanup_patterns = {
            'cache_dirs': {
                '__pycache__',
                '.pytest_cache',
                '.mypy_cache',
                'node_modules',
                '.coverage',
                'htmlcov'
            },
            'cache_files': {
                '*.pyc',
                '*.pyo',
                '*.pyd',
                '*.so',
                '.coverage',
                'coverage.xml'
            },
            'temp_files': {
                '*.tmp',
                '*.temp',
                '*.bak',
                '*.swp',
                '*.swo',
                '*~',
                '.DS_Store',
                'Thumbs.db'
            },
            'log_files_old': {
                # ä¿ç•™æœ€è¿‘çš„æ—¥å¿—ï¼Œåˆ é™¤æ—§çš„
                'logs/*-2023-*.log',  # 2023å¹´çš„æ—¥å¿—
                'logs/error-*.log',  # ç©ºçš„é”™è¯¯æ—¥å¿—
                'logs/warning-*.log'  # ç©ºçš„è­¦å‘Šæ—¥å¿—
            },
            'report_files_old': {
                'report/tmp/*',  # ä¸´æ—¶æŠ¥å‘Šæ–‡ä»¶
                'report/html/data/attachments/*'  # æ—§çš„é™„ä»¶
            }
        }

        # éœ€è¦ä¿ç•™çš„é‡è¦æ–‡ä»¶
        self.keep_files = {
            'requirements.txt',
            'pytest.ini',
            'pyproject.toml',
            '.flake8',
            '.pre-commit-config.yaml',
            'README.md',
            'run.py'
        }

        # é‡å¤çš„æ–‡æ¡£æ–‡ä»¶ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
        self.duplicate_docs = [
            'FINAL_PROJECT_STATUS.md',
            'FINAL_PROJECT_STATUS_COMPLETE.md',
            'FINAL_PROJECT_SUMMARY.md',
            'FINAL_OPTIMIZATION_SUMMARY.md',
            'FINAL_PERFECT_OPTIMIZATION_SUMMARY.md',
            'FINAL_STATUS_REPORT.md',
            'PROJECT_OPTIMIZATION_COMPLETE.md',
            'PROJECT_OPTIMIZATION_SUMMARY.md',
            'PROJECT_SUMMARY.md',
            'OPTIMIZATION_SUMMARY.md',
            'CONFIG_FIX_SUMMARY.md',
            'IMPORT_FIX_SUMMARY.md'
        ]

    def get_file_size(self, file_path: Path) -> int:
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            return file_path.stat().st_size
        except:
            return 0

    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f}KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f}MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f}GB"

    def clean_cache_dirs(self) -> List[str]:
        """æ¸…ç†ç¼“å­˜ç›®å½•"""
        cleaned = []

        for cache_dir in self.cleanup_patterns['cache_dirs']:
            cache_paths = list(self.project_root.rglob(cache_dir))

            for cache_path in cache_paths:
                if cache_path.is_dir():
                    try:
                        # è®¡ç®—ç›®å½•å¤§å°
                        dir_size = sum(self.get_file_size(f) for f in cache_path.rglob('*') if f.is_file())

                        shutil.rmtree(cache_path)
                        cleaned.append(str(cache_path))
                        self.saved_space += dir_size
                        self.stats['cache_files'] += 1

                        print(f"âœ… åˆ é™¤ç¼“å­˜ç›®å½•: {cache_path} ({self.format_size(dir_size)})")
                    except Exception as e:
                        print(f"âŒ åˆ é™¤ç¼“å­˜ç›®å½•å¤±è´¥ {cache_path}: {e}")

        return cleaned

    def clean_cache_files(self) -> List[str]:
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        cleaned = []

        for pattern in self.cleanup_patterns['cache_files']:
            if pattern.startswith('*'):
                # é€šé…ç¬¦æ¨¡å¼
                cache_files = list(self.project_root.rglob(pattern))
            else:
                # å…·ä½“æ–‡ä»¶
                cache_file = self.project_root / pattern
                cache_files = [cache_file] if cache_file.exists() else []

            for cache_file in cache_files:
                if cache_file.is_file():
                    try:
                        file_size = self.get_file_size(cache_file)
                        cache_file.unlink()
                        cleaned.append(str(cache_file))
                        self.saved_space += file_size
                        self.stats['cache_files'] += 1

                        print(f"âœ… åˆ é™¤ç¼“å­˜æ–‡ä»¶: {cache_file} ({self.format_size(file_size)})")
                    except Exception as e:
                        print(f"âŒ åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")

        return cleaned

    def clean_temp_files(self) -> List[str]:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        cleaned = []

        for pattern in self.cleanup_patterns['temp_files']:
            temp_files = list(self.project_root.rglob(pattern))

            for temp_file in temp_files:
                if temp_file.is_file():
                    try:
                        file_size = self.get_file_size(temp_file)
                        temp_file.unlink()
                        cleaned.append(str(temp_file))
                        self.saved_space += file_size
                        self.stats['temp_files'] += 1

                        print(f"âœ… åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file} ({self.format_size(file_size)})")
                    except Exception as e:
                        print(f"âŒ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")

        return cleaned

    def clean_old_logs(self) -> List[str]:
        """æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶"""
        cleaned = []
        logs_dir = self.project_root / 'logs'

        if not logs_dir.exists():
            return cleaned

        # æ¸…ç†2023å¹´çš„æ—¥å¿—æ–‡ä»¶
        old_logs = list(logs_dir.glob('*-2023-*.log'))

        # æ¸…ç†ç©ºçš„æ—¥å¿—æ–‡ä»¶
        for log_file in logs_dir.glob('*.log'):
            if log_file.stat().st_size == 0:
                old_logs.append(log_file)

        for log_file in old_logs:
            try:
                file_size = self.get_file_size(log_file)
                log_file.unlink()
                cleaned.append(str(log_file))
                self.saved_space += file_size
                self.stats['log_files'] += 1

                print(f"âœ… åˆ é™¤æ—§æ—¥å¿—: {log_file} ({self.format_size(file_size)})")
            except Exception as e:
                print(f"âŒ åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {e}")

        return cleaned

    def clean_old_reports(self) -> List[str]:
        """æ¸…ç†æ—§æŠ¥å‘Šæ–‡ä»¶"""
        cleaned = []

        # æ¸…ç†ä¸´æ—¶æŠ¥å‘Šæ–‡ä»¶
        report_tmp = self.project_root / 'report' / 'tmp'
        if report_tmp.exists():
            try:
                # è®¡ç®—ç›®å½•å¤§å°
                dir_size = sum(self.get_file_size(f) for f in report_tmp.rglob('*') if f.is_file())

                # ä¿ç•™ç›®å½•ï¼Œä½†æ¸…ç©ºå†…å®¹
                for item in report_tmp.iterdir():
                    if item.is_file():
                        item.unlink()
                    elif item.is_dir():
                        shutil.rmtree(item)

                cleaned.append(str(report_tmp))
                self.saved_space += dir_size
                self.stats['report_files'] += 1

                print(f"âœ… æ¸…ç†æŠ¥å‘Šä¸´æ—¶æ–‡ä»¶: {report_tmp} ({self.format_size(dir_size)})")
            except Exception as e:
                print(f"âŒ æ¸…ç†æŠ¥å‘Šæ–‡ä»¶å¤±è´¥ {report_tmp}: {e}")

        return cleaned

    def clean_duplicate_docs(self) -> List[str]:
        """æ¸…ç†é‡å¤çš„æ–‡æ¡£æ–‡ä»¶"""
        cleaned = []

        # ä¿ç•™æœ€é‡è¦çš„æ–‡æ¡£ï¼Œåˆ é™¤é‡å¤çš„
        keep_docs = {
            'README.md',
            'PROJECT_STRUCTURE.md',
            'DATA_DRIVER_GUIDE.md',
            'DEPLOYMENT_GUIDE.md',
            'CODE_OPTIMIZATION_FINAL_REPORT.md'
        }

        for doc_file in self.duplicate_docs:
            doc_path = self.project_root / doc_file
            if doc_path.exists() and doc_file not in keep_docs:
                try:
                    file_size = self.get_file_size(doc_path)
                    doc_path.unlink()
                    cleaned.append(str(doc_path))
                    self.saved_space += file_size
                    self.stats['duplicate_docs'] += 1

                    print(f"âœ… åˆ é™¤é‡å¤æ–‡æ¡£: {doc_file} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥ {doc_file}: {e}")

        return cleaned

    def clean_old_scripts(self) -> List[str]:
        """æ¸…ç†æ—§çš„è„šæœ¬æ–‡ä»¶"""
        cleaned = []

        # æ¸…ç†ä¸€äº›æµ‹è¯•å’Œè°ƒè¯•è„šæœ¬
        old_scripts = [
            'debug_excel_data.py',
            'test_encoding_fix.py',
            'test_excel_data_driver.py',
            'test_excel_execution.py',
            'test_functionality.py',
            'test_log_encoding.py',
            'verify_fixes.py',
            'final_quality_check.py',
            'project_optimization_check.py'
        ]

        for script in old_scripts:
            script_path = self.project_root / script
            if script_path.exists():
                try:
                    file_size = self.get_file_size(script_path)
                    script_path.unlink()
                    cleaned.append(str(script_path))
                    self.saved_space += file_size
                    self.stats['old_scripts'] += 1

                    print(f"âœ… åˆ é™¤æ—§è„šæœ¬: {script} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤è„šæœ¬å¤±è´¥ {script}: {e}")

        return cleaned

    def clean_json_reports(self) -> List[str]:
        """æ¸…ç†JSONæŠ¥å‘Šæ–‡ä»¶"""
        cleaned = []

        json_files = [
            'code_quality_report.json',
            'project_optimization_report.json'
        ]

        for json_file in json_files:
            json_path = self.project_root / json_file
            if json_path.exists():
                try:
                    file_size = self.get_file_size(json_path)
                    json_path.unlink()
                    cleaned.append(str(json_path))
                    self.saved_space += file_size

                    print(f"âœ… åˆ é™¤JSONæŠ¥å‘Š: {json_file} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤JSONæŠ¥å‘Šå¤±è´¥ {json_file}: {e}")

        return cleaned

    def clean_project(self, confirm: bool = True) -> Dict[str, Any]:
        """æ¸…ç†æ•´ä¸ªé¡¹ç›®"""
        if confirm:
            print("ğŸ§¹ å¼€å§‹é¡¹ç›®æ¸…ç†...")
            print("âš ï¸  è¿™å°†åˆ é™¤ç¼“å­˜ã€ä¸´æ—¶æ–‡ä»¶ã€æ—§æ—¥å¿—å’Œé‡å¤æ–‡æ¡£")
            response = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
            if response.lower() not in ['y', 'yes']:
                print("âŒ æ¸…ç†å·²å–æ¶ˆ")
                return {'cancelled': True}

        print("\nğŸš€ å¼€å§‹æ¸…ç†é¡¹ç›®...")
        start_time = time.time()

        # æ‰§è¡Œå„ç§æ¸…ç†
        self.cleaned_files.extend(self.clean_cache_dirs())
        self.cleaned_files.extend(self.clean_cache_files())
        self.cleaned_files.extend(self.clean_temp_files())
        self.cleaned_files.extend(self.clean_old_logs())
        self.cleaned_files.extend(self.clean_old_reports())
        self.cleaned_files.extend(self.clean_duplicate_docs())
        self.cleaned_files.extend(self.clean_old_scripts())
        self.cleaned_files.extend(self.clean_json_reports())

        end_time = time.time()

        # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        report = {
            'total_files_cleaned': len(self.cleaned_files),
            'space_saved': self.format_size(self.saved_space),
            'space_saved_bytes': self.saved_space,
            'cleanup_time': f"{end_time - start_time:.2f}ç§’",
            'stats': self.stats,
            'cleaned_files': self.cleaned_files[:20]  # åªæ˜¾ç¤ºå‰20ä¸ª
        }

        return report

    def generate_cleanup_summary(self, report: Dict[str, Any]):
        """ç”Ÿæˆæ¸…ç†æ‘˜è¦"""
        print(f"\nğŸ“Š æ¸…ç†å®Œæˆæ‘˜è¦:")
        print(f"   æ¸…ç†æ–‡ä»¶æ•°: {report['total_files_cleaned']}")
        print(f"   èŠ‚çœç©ºé—´: {report['space_saved']}")
        print(f"   æ¸…ç†æ—¶é—´: {report['cleanup_time']}")

        print(f"\nğŸ“‹ æ¸…ç†ç»Ÿè®¡:")
        for category, count in report['stats'].items():
            if count > 0:
                print(f"   {category}: {count}")

        if report['cleaned_files']:
            print(f"\nğŸ“ æ¸…ç†çš„æ–‡ä»¶ (å‰20ä¸ª):")
            for file_path in report['cleaned_files']:
                print(f"   - {file_path}")

        print(f"\nğŸ’¡ å»ºè®®:")
        print("   1. è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸:")
        print("      python -m pytest test_case/Login/test_login.py -v")
        print("   2. é‡æ–°ç”ŸæˆæŠ¥å‘Š:")
        print("      python -m pytest test_case/ --alluredir=./report/tmp")
        print("   3. å®šæœŸæ¸…ç†ä»¥ä¿æŒé¡¹ç›®æ•´æ´")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="é¡¹ç›®æ¸…ç†å·¥å…·")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¸…ç†ï¼Œä¸éœ€è¦ç¡®è®¤")
    parser.add_argument("--dry-run", action="store_true", help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶")

    args = parser.parse_args()

    cleaner = ProjectCleaner()

    if args.dry_run:
        print("ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡æ‹Ÿè¿è¡Œçš„é€»è¾‘
        return

    report = cleaner.clean_project(confirm=not args.auto)

    if not report.get('cancelled'):
        cleaner.generate_cleanup_summary(report)


if __name__ == "__main__":
    main()
