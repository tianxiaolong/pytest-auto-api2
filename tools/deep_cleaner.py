#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Deep Cleaner Module

This module provides deep cleaner functionality.
"""

"""
æ·±åº¦æ¸…ç†å·¥å…·
æ¸…ç†é¡¹ç›®ä¸­çš„é‡å¤æ–‡æ¡£ã€æµ‹è¯•è„šæœ¬å’Œæ— ç”¨æ–‡ä»¶

@Time   : 2023-12-20
@Author : txl
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import time


class DeepCleaner:
    """æ·±åº¦æ¸…ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.cleaned_files = []
        self.saved_space = 0
        
        # éœ€è¦åˆ é™¤çš„é‡å¤æ–‡æ¡£
        self.duplicate_docs = [
            'FINAL_PROJECT_STATUS.md',
            'FINAL_PROJECT_STATUS_COMPLETE.md',
            'FINAL_OPTIMIZATION_SUMMARY.md', 
            'FINAL_PERFECT_OPTIMIZATION_SUMMARY.md',
            'FINAL_STATUS_REPORT.md',
            'PROJECT_OPTIMIZATION_COMPLETE.md',
            'PROJECT_OPTIMIZATION_SUMMARY.md',
            'PROJECT_SUMMARY.md',
            'OPTIMIZATION_SUMMARY.md',
            'CONFIG_FIX_SUMMARY.md',
            'IMPORT_FIX_SUMMARY.md',
            'README_NEW.md'  # å·²ç»åˆå¹¶åˆ°README.md
        ]
        
        # éœ€è¦åˆ é™¤çš„æµ‹è¯•å’Œè°ƒè¯•è„šæœ¬
        self.test_scripts = [
            'debug_excel_data.py',
            'test_encoding_fix.py',
            'test_excel_data_driver.py',
            'test_excel_execution.py',
            'test_functionality.py',
            'test_log_encoding.py',
            'verify_fixes.py',
            'final_quality_check.py',
            'project_optimization_check.py'
        ]
        
        # éœ€è¦åˆ é™¤çš„JSONæŠ¥å‘Šæ–‡ä»¶
        self.json_reports = [
            'code_quality_report.json',
            'project_optimization_report.json',
            'performance_report.json'
        ]
        
        # ä¿ç•™çš„é‡è¦æ–‡æ¡£
        self.keep_docs = {
            'README.md',
            'PROJECT_STRUCTURE.md',
            'DATA_DRIVER_GUIDE.md',
            'DEPLOYMENT_GUIDE.md',
            'CODE_OPTIMIZATION_FINAL_REPORT.md',
            'FINAL_PROJECT_SUMMARY.md'  # æœ€ç»ˆæ€»ç»“ä¿ç•™
        }
    
    def get_file_size(self, file_path: Path) -> int:
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            return file_path.stat().st_size
        except:
            return 0
    
    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes/1024:.1f}KB"
        else:
            return f"{size_bytes/(1024*1024):.1f}MB"
    
    def clean_duplicate_docs(self) -> List[str]:
        """æ¸…ç†é‡å¤æ–‡æ¡£"""
        cleaned = []
        
        print("ğŸ“ æ¸…ç†é‡å¤æ–‡æ¡£...")
        
        for doc_file in self.duplicate_docs:
            doc_path = self.project_root / doc_file
            if doc_path.exists():
                try:
                    file_size = self.get_file_size(doc_path)
                    doc_path.unlink()
                    cleaned.append(str(doc_path))
                    self.saved_space += file_size
                    
                    print(f"âœ… åˆ é™¤é‡å¤æ–‡æ¡£: {doc_file} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥ {doc_file}: {e}")
        
        return cleaned
    
    def clean_test_scripts(self) -> List[str]:
        """æ¸…ç†æµ‹è¯•è„šæœ¬"""
        cleaned = []
        
        print("\nğŸ§ª æ¸…ç†æµ‹è¯•å’Œè°ƒè¯•è„šæœ¬...")
        
        for script in self.test_scripts:
            script_path = self.project_root / script
            if script_path.exists():
                try:
                    file_size = self.get_file_size(script_path)
                    script_path.unlink()
                    cleaned.append(str(script_path))
                    self.saved_space += file_size
                    
                    print(f"âœ… åˆ é™¤æµ‹è¯•è„šæœ¬: {script} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤è„šæœ¬å¤±è´¥ {script}: {e}")
        
        return cleaned
    
    def clean_json_reports(self) -> List[str]:
        """æ¸…ç†JSONæŠ¥å‘Š"""
        cleaned = []
        
        print("\nğŸ“Š æ¸…ç†JSONæŠ¥å‘Šæ–‡ä»¶...")
        
        for json_file in self.json_reports:
            json_path = self.project_root / json_file
            if json_path.exists():
                try:
                    file_size = self.get_file_size(json_path)
                    json_path.unlink()
                    cleaned.append(str(json_path))
                    self.saved_space += file_size
                    
                    print(f"âœ… åˆ é™¤JSONæŠ¥å‘Š: {json_file} ({self.format_size(file_size)})")
                except Exception as e:
                    print(f"âŒ åˆ é™¤JSONæŠ¥å‘Šå¤±è´¥ {json_file}: {e}")
        
        return cleaned
    
    def clean_old_logs(self) -> List[str]:
        """æ¸…ç†æ—§æ—¥å¿—"""
        cleaned = []
        
        print("\nğŸ“‹ æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶...")
        
        logs_dir = self.project_root / 'logs'
        if logs_dir.exists():
            # æ¸…ç†ç©ºçš„æ—¥å¿—æ–‡ä»¶
            for log_file in logs_dir.glob('*.log'):
                if log_file.stat().st_size == 0:
                    try:
                        log_file.unlink()
                        cleaned.append(str(log_file))
                        print(f"âœ… åˆ é™¤ç©ºæ—¥å¿—: {log_file.name}")
                    except Exception as e:
                        print(f"âŒ åˆ é™¤æ—¥å¿—å¤±è´¥ {log_file}: {e}")
        
        return cleaned
    
    def scan_large_files(self) -> List[Dict[str, Any]]:
        """æ‰«æå¤§æ–‡ä»¶"""
        large_files = []
        
        print("\nğŸ” æ‰«æå¤§æ–‡ä»¶...")
        
        for file_path in self.project_root.rglob('*'):
            if file_path.is_file() and 'venv' not in str(file_path):
                file_size = self.get_file_size(file_path)
                if file_size > 1024 * 1024:  # å¤§äº1MB
                    large_files.append({
                        'path': str(file_path.relative_to(self.project_root)),
                        'size': file_size,
                        'size_str': self.format_size(file_size)
                    })
        
        # æŒ‰å¤§å°æ’åº
        large_files.sort(key=lambda x: x['size'], reverse=True)
        
        if large_files:
            print("ğŸ“Š å‘ç°çš„å¤§æ–‡ä»¶:")
            for file_info in large_files[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"   {file_info['path']} - {file_info['size_str']}")
        
        return large_files
    
    def clean_project(self) -> Dict[str, Any]:
        """æ·±åº¦æ¸…ç†é¡¹ç›®"""
        print("ğŸ§¹ å¼€å§‹æ·±åº¦æ¸…ç†é¡¹ç›®...")
        print("=" * 60)
        
        start_time = time.time()
        
        # æ‰§è¡Œå„ç§æ¸…ç†
        self.cleaned_files.extend(self.clean_duplicate_docs())
        self.cleaned_files.extend(self.clean_test_scripts())
        self.cleaned_files.extend(self.clean_json_reports())
        self.cleaned_files.extend(self.clean_old_logs())
        
        # æ‰«æå¤§æ–‡ä»¶
        large_files = self.scan_large_files()
        
        end_time = time.time()
        
        # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        report = {
            'total_files_cleaned': len(self.cleaned_files),
            'space_saved': self.format_size(self.saved_space),
            'space_saved_bytes': self.saved_space,
            'cleanup_time': f"{end_time - start_time:.2f}ç§’",
            'cleaned_files': self.cleaned_files,
            'large_files': large_files
        }
        
        return report
    
    def generate_cleanup_summary(self, report: Dict[str, Any]):
        """ç”Ÿæˆæ¸…ç†æ‘˜è¦"""
        print(f"\nğŸ“Š æ·±åº¦æ¸…ç†å®Œæˆæ‘˜è¦:")
        print(f"   æ¸…ç†æ–‡ä»¶æ•°: {report['total_files_cleaned']}")
        print(f"   èŠ‚çœç©ºé—´: {report['space_saved']}")
        print(f"   æ¸…ç†æ—¶é—´: {report['cleanup_time']}")
        
        if report['cleaned_files']:
            print(f"\nğŸ“ æ¸…ç†çš„æ–‡ä»¶:")
            for file_path in report['cleaned_files']:
                print(f"   - {file_path}")
        
        if report['large_files']:
            print(f"\nğŸ“Š å¤§æ–‡ä»¶æé†’ (>1MB):")
            for file_info in report['large_files'][:5]:
                print(f"   {file_info['path']} - {file_info['size_str']}")
        
        print(f"\nâœ… ä¿ç•™çš„é‡è¦æ–‡æ¡£:")
        for doc in sorted(self.keep_docs):
            doc_path = self.project_root / doc
            if doc_path.exists():
                size = self.format_size(self.get_file_size(doc_path))
                print(f"   âœ“ {doc} ({size})")
        
        print(f"\nğŸ’¡ æ¸…ç†åå»ºè®®:")
        print("   1. éªŒè¯æµ‹è¯•åŠŸèƒ½æ­£å¸¸:")
        print("      python -m pytest test_case/Login/test_login.py -v")
        print("   2. æ£€æŸ¥é¡¹ç›®ç»“æ„:")
        print("      python tools/project_structure_analyzer.py")
        print("   3. è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥:")
        print("      python tools/smart_quality_checker.py --mode relaxed")


def main():
    """ä¸»å‡½æ•°"""
    cleaner = DeepCleaner()
    report = cleaner.clean_project()
    cleaner.generate_cleanup_summary(report)


if __name__ == "__main__":
    main()
